{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysisBERT_Local.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeroxenator/rug-ltp-project/blob/master/SentimentAnalysisBERT_Local.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxqUbCzVlloB",
        "colab_type": "text"
      },
      "source": [
        "# **Preparing Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UifczJu0-yh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "outputId": "95068c6f-8d78-4b24-feb7-51d175c41a1e"
      },
      "source": [
        "!pip install pytorch_pretrained_bert\n",
        "!pip install torch torchvision\n",
        "!pip install pytorch-nlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.16.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.21.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.1.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.9.162)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.6.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.3.9)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.162 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.12.162)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.162->boto3->pytorch_pretrained_bert) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.162->boto3->pytorch_pretrained_bert) (0.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.162->boto3->pytorch_pretrained_bert) (1.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (0.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (1.16.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (4.28.1)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->pytorch-nlp) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->pytorch-nlp) (2.5.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-nlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-nlp) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-nlp) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-nlp) (2.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas->pytorch-nlp) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWiyoDOFkzZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwWJgQhR-kg2",
        "colab_type": "text"
      },
      "source": [
        "## Load IMDB dataset from torchnlp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZgujfSY-phn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random as rn\n",
        "from torchnlp.datasets import imdb_dataset\n",
        "\n",
        "rn.seed(321)\n",
        "\n",
        "org_train_data, org_test_data = imdb_dataset(train=True, test=True)\n",
        "rn.shuffle(org_train_data)\n",
        "rn.shuffle(org_test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHEc4r5UPqPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "d31f2364-f67b-47b7-94a5-fd67634fc2b0"
      },
      "source": [
        "train_data = org_train_data[:1000]\n",
        "valid_data = org_train_data[1001:1501]\n",
        "test_data = org_test_data[:100]\n",
        "\n",
        "print(len(train_data))\n",
        "print(len(valid_data))\n",
        "print(len(test_data))\n",
        "\n",
        "print(train_data[0])\n",
        "print(valid_data[0])\n",
        "print(test_data[0])\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "500\n",
            "100\n",
            "{'text': \"I stumbled upon this movie on cable and was totally hooked. The story of a group of surfers who ride the big waves, waves that are monstrously huge, waves that would make any rational person run away in terror is a one that manages to be spectacular and make you understand why people spend their lives chasing waves. There is nothing special about the film, other than it brings together some very interesting people who are are in love with what they do and lets them talk. Sure there are scenes of them surfing, but what makes this movie so special is the people. Here are a bunch of guys who are so enthusiastic about what they do that it crosses over to the people watching. Half way into this movie you'll want to go off and learn to surf as well. Few documentaries have ever managed to covey the passion that these people have and its the films ability to make us feel it that makes this a great film. See it.\", 'sentiment': 'pos'}\n",
            "{'text': \"Joshua Seftel's first film - a satire of memorable proportions - is about just as the title suggests: The corporations effect on War.<br /><br />The film is about a mercenary (John Cusack) traveling to Turaqistan (not a real country, fyi) to help the American government 'get their message across' to Turaqistan's leaders. He meets a reporter (Marisa Tomei) and we all know what will ensue with a lonely man + a hot reporter. Somewhere in the mix, a pop star named Yonica Babyyeah gets thrown in. As Yonica is marrying one of Turaquistan's most important people (a son of the president), a subplot is created where the mercenary must watch over this star, well, somewhat. The film starts off with a lonely Cusack in a bar; no more than fifteen seconds later, the film hooks you. With it's amusing and intriguing insight on terrorism and politics, the film's running time blows by you. The film has a lot more action than I expected, with the occasional scene of war, well choreographed fights and just sporadic scenes of murder. Though the story isn't much deep, the simplicity of it all makes the film perfect for both the common man and movie critics alike.<br /><br />In the final act of the film, the simplicity of it all turns very hostile and jumbled. I thought it was executed very well, but other may disagree, and I could understand why. Twist after twist is what the ending is all about, and like most films, it is a true hit/miss situation. Regardless, the three writers on the film (Mark Leyner, Jeremy Pikser & John Cusack) did a fantastic job creating a realistic and entertaining satire on today's situation overseas.<br /><br />Joshua Seftel does an excellent job insuring the film's integrity; not reducing the material to the most redundant of films (which I was afraid would happen). Seftel crafted the film as perfectly as one could: he created a vibrant atmosphere, one that is both examines harsh reality and cartoonish falsities; - contrasting them perfectly - as well as making the film feel as if you were watching it all. Seftel really gets you involved in all of the action and it pays off completely. No missteps here. Hopefully, he takes on more directorial jobs, for he is one director to look out for.\", 'sentiment': 'pos'}\n",
            "{'text': 'This classic has so many great one-liners and unintentionally hilarious scenes that I don\\'t even know where to start. If you want advice on dating, its here. Just totally ignore the person you want, and then spout out classic lines like \"Chicken\\'s good...I like Chicken\", and before you know it you will be having a one-nighter in a basement (it\\'s a NICE basement) with a woman who is 35 years younger than you. Bronson does it all in this film. He buys a car for no good reason just so he can murder two gang members...paying with \"CASH\"......chunnng.... He buys an ice cream, simply because \"this is America, isn\\'t it\", and ends up wasting someone named \"the giggler - he laughs when he runs\" just because he stole his camera. By the way, this \"giggler\" is so fast that Bronson\\'s regular pistol can\\'t even catch up to him, he needs to order a special one just to get this elusive creep. He gets cleaned up just so he can eat a REALLY smelly meal (stuffed cabbage) in a rat trap with a couple of old people who like to wear heavy clothing in 90 degree weather. He goes into the dentistry business. He always seems to find a crow bar when he needs one (and its the same one!). And last, but not least, he always seems to have a rocket launcher at his disposal just in case he needs to blow away Richie Cunningham\\'s older brother Chuck who is now strung out and in dire need of a makeover. Anyway, this will all make sense once you have seen this classic...all I can say is enjoy! \"I owed you that one DUDE\"', 'sentiment': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb3NO6N39h-L",
        "colab_type": "text"
      },
      "source": [
        "Using pre-trained tokens from Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl87ZKib9ekv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8370d2b3-db87-4771-9f8e-a783e6b69b1f"
      },
      "source": [
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "train_texts, train_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), train_data)))\n",
        "valid_texts, valid_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), valid_data)))\n",
        "test_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), test_data)))\n",
        "\n",
        "print(len(train_texts), len(train_labels), len(valid_texts), len(valid_labels), len(test_texts), len(test_labels))\n",
        "\n",
        "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], train_texts))\n",
        "valid_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], valid_texts))\n",
        "test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], test_texts))\n",
        "\n",
        "len(train_tokens), len(valid_tokens), len(test_tokens)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 1000 500 500 100 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 500, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdU-KDdo_Y3I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "660dfd5b-9d6b-4a20-b400-cc8c8d2edb08"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "train_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, train_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "valid_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, valid_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "test_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, test_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "\n",
        "train_tokens_ids.shape, valid_tokens_ids.shape, test_tokens_ids.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 512), (500, 512), (100, 512))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz1YF7eI_liD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b7762cb-3026-4c1f-be6b-67a2cd0d9b1f"
      },
      "source": [
        "import numpy as np\n",
        "train_y = np.array(train_labels) == 'pos'\n",
        "valid_y = np.array(valid_labels) == 'pos'\n",
        "test_y = np.array(test_labels) == 'pos'\n",
        "train_y.shape, valid_y.shape, test_y.shape, np.mean(train_y), np.mean(valid_y), np.mean(test_y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000,), (500,), (100,), 0.489, 0.496, 0.5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlZ4xv-y_u3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
        "valid_masks = [[float(i > 0) for i in ii] for ii in valid_tokens_ids]\n",
        "test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O67tRmAV_yK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tokens_ids[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhCNWk3qle-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQGNO8NVKuqw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "82b25984-78e3-455a-cf8c-fd5e9660dde8"
      },
      "source": [
        "train_iterator\n",
        "\n",
        "from torchtext import data\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_texts, valid_texts, test_texts), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-081c7feec9c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msort_within_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     device = device)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36msplits\u001b[0;34m(cls, datasets, batch_sizes, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             ret.append(cls(\n\u001b[0;32m---> 97\u001b[0;31m                 datasets[i], batch_size=batch_sizes[i], train=train, **kwargs))\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, sort_key, device, batch_size_fn, train, repeat, shuffle, sort, sort_within_batch)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_within_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msort_within_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msort_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msort_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'sort_key'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBPSpo4rl7io",
        "colab_type": "text"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL7Dl4xsl_5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, embedding_matrix, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float))\n",
        "        #self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.rnn = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        #pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        \n",
        "        #unpack sequence\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * num directions]\n",
        "        #output over padding tokens are zero tensors\n",
        "        \n",
        "        #hidden = [num layers * num directions, batch size, hid dim]\n",
        "        #cell = [num layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        #and apply dropout\n",
        "        \n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "            \n",
        "        return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCKP1slGmIAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(train_tokens_ids)\n",
        "EMBEDDING_DIM = 512\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "#PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = RNN(train_tokens_ids, INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gx-YfjAmLn_",
        "colab_type": "code",
        "outputId": "13e67238-5568-4a05-cda8-b1d2ab884836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 3,154,433 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyo3R2T9mM4s",
        "colab_type": "code",
        "outputId": "f384c6e5-3510-43da-8485-2f1a376a9d8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pretrained_embeddings = torch.Tensor(train_tokens_ids)\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZSMYnG2mN-8",
        "colab_type": "code",
        "outputId": "db86951c-0c01-4607-b07d-6a2a708c536f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 101., 1045., 9845.,  ...,    0.,    0.,    0.],\n",
              "        [ 101., 1000., 2028.,  ...,    0.,    0.,    0.],\n",
              "        [ 101., 1037., 2980.,  ...,    0.,    0.,    0.],\n",
              "        ...,\n",
              "        [ 101., 2672., 2025.,  ...,    0.,    0.,    0.],\n",
              "        [ 101., 2292., 1005.,  ...,    0.,    0.,    0.],\n",
              "        [ 101., 1000., 2265.,  ...,    0.,    0.,    0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKF2qlCAYtQF",
        "colab_type": "text"
      },
      "source": [
        "Set the unknown parameters to zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i_5r1uKmPKe",
        "colab_type": "code",
        "outputId": "7dcfaf0d-82d2-4b2d-b001-b02a6a00f63f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "t = pretrained_embeddings\n",
        "print (model.embedding.weight.data[(t == 101.).nonzero()])\n",
        "\n",
        "# UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "# model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "# model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "# print(model.embedding.weight.data)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 101., 1045., 9845.,  ...,    0.,    0.,    0.],\n",
            "         [ 101., 1045., 9845.,  ...,    0.,    0.,    0.]],\n",
            "\n",
            "        [[ 101., 1000., 2028.,  ...,    0.,    0.,    0.],\n",
            "         [ 101., 1045., 9845.,  ...,    0.,    0.,    0.]],\n",
            "\n",
            "        [[ 101., 1037., 2980.,  ...,    0.,    0.,    0.],\n",
            "         [ 101., 1045., 9845.,  ...,    0.,    0.,    0.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 101., 2672., 2025.,  ...,    0.,    0.,    0.],\n",
            "         [ 101., 1045., 9845.,  ...,    0.,    0.,    0.]],\n",
            "\n",
            "        [[ 101., 2292., 1005.,  ...,    0.,    0.,    0.],\n",
            "         [ 101., 1045., 9845.,  ...,    0.,    0.,    0.]],\n",
            "\n",
            "        [[ 101., 1000., 2265.,  ...,    0.,    0.,    0.],\n",
            "         [ 101., 1045., 9845.,  ...,    0.,    0.,    0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbXJVAK-mQCw",
        "colab_type": "text"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE4bb7JPmTAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CtC7nIXmU5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVF8E5cMmWUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_OieIT8mXfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        text, text_lengths = batch.text\n",
        "        \n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOSLjrXdmY97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text, text_lengths = batch.text\n",
        "            \n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjIsRHdnmb1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSTaojjXmee-",
        "colab_type": "code",
        "outputId": "2d40ffaf-d891-42a0-de4f-9f54f0393d3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r100%|█████████▉| 399622/400000 [00:30<00:00, 23879.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 41s\n",
            "\tTrain Loss: 0.670 | Train Acc: 58.50%\n",
            "\t Val. Loss: 0.700 |  Val. Acc: 50.75%\n",
            "Epoch: 02 | Epoch Time: 0m 42s\n",
            "\tTrain Loss: 0.658 | Train Acc: 60.35%\n",
            "\t Val. Loss: 0.605 |  Val. Acc: 66.71%\n",
            "Epoch: 03 | Epoch Time: 0m 42s\n",
            "\tTrain Loss: 0.559 | Train Acc: 71.37%\n",
            "\t Val. Loss: 0.433 |  Val. Acc: 80.81%\n",
            "Epoch: 04 | Epoch Time: 0m 43s\n",
            "\tTrain Loss: 0.464 | Train Acc: 79.12%\n",
            "\t Val. Loss: 0.351 |  Val. Acc: 85.36%\n",
            "Epoch: 05 | Epoch Time: 0m 43s\n",
            "\tTrain Loss: 0.338 | Train Acc: 85.87%\n",
            "\t Val. Loss: 0.307 |  Val. Acc: 87.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVC7mUClmf3s",
        "colab_type": "code",
        "outputId": "910f119c-0134-4701-fb61-dad50cbc2dda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.325 | Test Acc: 86.43%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}